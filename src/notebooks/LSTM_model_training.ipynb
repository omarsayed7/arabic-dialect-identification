{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-model-training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r85N2vYQjR13"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import callbacks\n",
        "from keras.preprocessing.text import Tokenizer  \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "import pickle\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For google colab we mount google drive \n",
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-YhOK8t_YXp",
        "outputId": "623df3c4-2511-48c3-9595-27a20dcabc7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_data_path = \"/content/drive/MyDrive/preprocessed_tweets.csv\""
      ],
      "metadata": {
        "id": "nrNnA4Ni_aJ8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(tweets_data_path)\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BSc1OIQ_bC1",
        "outputId": "924ed630-b638-4fee-a9e0-01fcb828fa4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 458197 entries, 0 to 458196\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   Unnamed: 0    458197 non-null  int64 \n",
            " 1   Unnamed: 0.1  458197 non-null  int64 \n",
            " 2   id            458197 non-null  int64 \n",
            " 3   dialect       458197 non-null  int64 \n",
            " 4   tweets        457992 non-null  object\n",
            "dtypes: int64(4), object(1)\n",
            "memory usage: 17.5+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.tweets.values.astype(str)\n",
        "lables = pd.get_dummies(df['dialect']).values #One-hot encoding the lables"
      ],
      "metadata": {
        "id": "HvCqqgAr_euH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000\n",
        "max_length= 300\n",
        "tokenizer = Tokenizer(num_words=vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=False)\n",
        "tokenizer.fit_on_texts(features)"
      ],
      "metadata": {
        "id": "4hJBOO5uZMWn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Found %s unique tokens.' % len(tokenizer.word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA9c19fOZZB5",
        "outputId": "c8f1963e-7c1e-41fe-8bbd-7771ed6c588c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 422859 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, lables, random_state=42, test_size=0.1, shuffle=True)"
      ],
      "metadata": {
        "id": "UQFK_rG2_7xn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42, test_size=0.1, shuffle=True)"
      ],
      "metadata": {
        "id": "GS13en1ZAPyU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape, y_val.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iimDH4hFAQPW",
        "outputId": "211d67bb-7f4a-4bff-f996-0544c4b4007c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((371139, 18), (41238, 18), (45820, 18))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_val.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0rEOj_jARkx",
        "outputId": "4a88674f-13da-4623-d313-f076f4a5b9cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((371139,), (41238,), (45820,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tok = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_tok = pad_sequences(X_train_tok, maxlen=max_length)\n",
        "print('Shape of data tensor:', X_train_tok.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VISG2S_MbTyE",
        "outputId": "e220f6f3-57a8-4f5c-da0a-89ec6856032d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (371139, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_tok = tokenizer.texts_to_sequences(X_val)\n",
        "X_val_tok = pad_sequences(X_val_tok, maxlen=max_length)\n",
        "print('Shape of data tensor:', X_val_tok.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGAHFIWucYsy",
        "outputId": "a1a8ed39-c7b7-4b76-c5f1-e4711b833ae7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (41238, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tok = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_tok = pad_sequences(X_test_tok, maxlen=max_length)\n",
        "print('Shape of data tensor:', X_test_tok.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O13EejbYeRo_",
        "outputId": "7004aab1-f816-4a06-c707-76a83076164e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (45820, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM Model**"
      ],
      "metadata": {
        "id": "KejM02KCA-wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "output_dim = 100\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "ZbBdl2Oqfcw9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/Arabic_dialect_models/lstm_model.h5\", monitor='loss', verbose=1,save_best_only=True, mode='auto', period=1)"
      ],
      "metadata": {
        "id": "h60B0sIrjfj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6938cd20-e266-41d4-fb4b-e8e2ffba0ced"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.load_model('/content/drive/MyDrive/Arabic_dialect_models/lstm_best_model.h5')"
      ],
      "metadata": {
        "id": "Gqx3L4vOIwiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc4abce-edd4-4137-9bbf-3da7d401ad12"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(Embedding(vocab_size, output_dim, input_shape=(max_length,)))\n",
        "model.add(SpatialDropout1D(0.5))\n",
        "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "model.add(Dense(18, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_tok, y_train, epochs=epochs, batch_size=batch_size,validation_data=(X_val_tok, y_val), callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "S1r8cgFNANYF",
        "outputId": "bfc3456e-38cd-4349-8c8b-3b1de3a2cffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "5800/5800 [==============================] - ETA: 0s - loss: 1.9869 - accuracy: 0.3696\n",
            "Epoch 1: loss improved from inf to 1.98692, saving model to lstm_best_model.h5\n",
            "5800/5800 [==============================] - 5185s 893ms/step - loss: 1.9869 - accuracy: 0.3696 - val_loss: 1.7051 - val_accuracy: 0.4637\n",
            "Epoch 2/2\n",
            "5800/5800 [==============================] - ETA: 0s - loss: 1.6902 - accuracy: 0.4688\n",
            "Epoch 2: loss improved from 1.98692 to 1.69025, saving model to lstm_best_model.h5\n",
            "5800/5800 [==============================] - 5165s 890ms/step - loss: 1.6902 - accuracy: 0.4688 - val_loss: 1.6346 - val_accuracy: 0.4875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_tok, y_train, epochs=epochs, batch_size=batch_size,validation_data=(X_val_tok, y_val), callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm0pvTmKTLxT",
        "outputId": "d710ad8f-4253-4e26-9474-9caa99c09d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5800/5800 [==============================] - ETA: 0s - loss: 1.5428 - accuracy: 0.5155\n",
            "Epoch 1: loss improved from 1.59976 to 1.54278, saving model to lstm_best_model.h5\n",
            "5800/5800 [==============================] - 4998s 861ms/step - loss: 1.5428 - accuracy: 0.5155 - val_loss: 1.6050 - val_accuracy: 0.4963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_tok, y_train, epochs=epochs, batch_size=batch_size,validation_data=(X_val_tok, y_val), callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nwacfls7wYE",
        "outputId": "8a8fe065-3fd7-4a8d-9edd-312a035a2997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5800/5800 [==============================] - ETA: 0s - loss: 1.5023 - accuracy: 0.5275\n",
            "Epoch 1: loss improved from 1.54278 to 1.50234, saving model to lstm_best_model.h5\n",
            "5800/5800 [==============================] - 5127s 884ms/step - loss: 1.5023 - accuracy: 0.5275 - val_loss: 1.6058 - val_accuracy: 0.4974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.load_model('/content/drive/MyDrive/Arabic_dialect_models/lstm_model.h5')# loading\n",
        "# loading\n",
        "max_length= 300\n",
        "with open('/content/drive/MyDrive/Arabic_dialect_models/lstm_tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "metadata": {
        "id": "a1iQoBzAgfmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00af6c2-3e74-45fb-d850-14674d130222"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_tok, y_test, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSlbTJa2zjST",
        "outputId": "badc4ebd-a2ba-47fa-daf8-cb4ce2b3a0d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "716/716 [==============================] - 80s 109ms/step - loss: 1.6088 - accuracy: 0.4949\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6087932586669922, 0.49487122893333435]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Calculating the classification report\")\n",
        "y_pred = model.predict(X_test_tok, batch_size=512, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_test_report = np.argmax(y_test, axis=1)\n",
        "print(\n",
        "    f\"Classification Report : \\n\\n{classification_report(y_test_report, y_pred_bool)}\")"
      ],
      "metadata": {
        "id": "rY9WCLQAlxq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842d492c-5f25-4380-9f45-c53e23409ffb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Calculating the classification report\n",
            "90/90 [==============================] - 20s 224ms/step\n",
            "Classification Report : \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.36      0.39      2753\n",
            "           1       0.29      0.28      0.29      2647\n",
            "           2       0.54      0.49      0.51      1678\n",
            "           3       0.64      0.84      0.73      5691\n",
            "           4       0.54      0.50      0.52      1510\n",
            "           5       0.42      0.27      0.33      2858\n",
            "           6       0.42      0.52      0.46      4157\n",
            "           7       0.56      0.68      0.61      2860\n",
            "           8       0.58      0.63      0.60      3664\n",
            "           9       0.69      0.55      0.61      1110\n",
            "          10       0.34      0.31      0.32      1904\n",
            "          11       0.45      0.51      0.48      4263\n",
            "          12       0.47      0.41      0.44      3114\n",
            "          13       0.35      0.41      0.38      2653\n",
            "          14       0.69      0.54      0.60      1432\n",
            "          15       0.49      0.26      0.34      1611\n",
            "          16       0.66      0.35      0.46       916\n",
            "          17       0.37      0.18      0.24       999\n",
            "\n",
            "    accuracy                           0.49     45820\n",
            "   macro avg       0.50      0.45      0.46     45820\n",
            "weighted avg       0.49      0.49      0.48     45820\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_complaint = ['شلونك شو تسوي ']\n",
        "seq = tokenizer.texts_to_sequences(new_complaint)\n",
        "padded = pad_sequences(seq, maxlen=max_length)\n",
        "pred = model.predict(padded)\n",
        "CLASS_DICT = {0: \"AE\", 1: \"BH\", 2: \"DZ\", 3: \"EG\", 4: \"IQ\", 5: \"JO\", 6: \"KW\", 7: \"LB\", 8: \"LY\", 9: \"MA\",\n",
        "              10: \"OM\", 11: \"PL\", 12: \"QA\", 13: \"SA\", 14: \"SD\", 15: \"SY\", 16: \"TN\", 17: \"YE\"}\n",
        "print(pred, CLASS_DICT[np.argmax(pred)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqJR11yoexG1",
        "outputId": "a85880d7-f195-42e1-fafa-cf56bd950847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.24816488 0.04875014 0.01015061 0.001222   0.12700514 0.11624358\n",
            "  0.09715858 0.02003108 0.00512088 0.00527489 0.10820533 0.07317767\n",
            "  0.01700952 0.01626699 0.00129211 0.09270472 0.00224872 0.00997321]] AE\n"
          ]
        }
      ]
    }
  ]
}